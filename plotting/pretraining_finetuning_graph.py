import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patheffects as path_effects

finetune_gin_val_losses =[1.09230440375974528, 0.5044897749419388, 0.47142933845931845, 0.4641778564573505, 0.45880151598278446, 0.4399232766507841, 0.42359172229464476, 0.40451293699916824, 0.39392678873405784, 0.40359197908646766, 0.39270709582463614, 0.4016519728251332, 0.3984475096622741, 0.4011697434197731, 0.39608127533317605, 0.3971445247938906, 0.3952316720589839, 0.39608904587819815, 0.3946389521459865, 0.3961500656561255, 0.39454280938144115, 0.3994892199531327, 0.39282271457424284, 0.3961444240350417, 0.39303751525758207, 0.397306783219858, 0.3984495924561874, 0.39552697616193705, 0.39663621049060394, 0.39667334956901124, 0.39643907106286524, 0.40014053890253387, 0.3958428282510555, 0.3984651725884085, 0.4029415456185068, 0.3950157915008318, 0.39778909907995125, 0.39195480399348814, 0.3938067781399268, 0.3937006313086731, 0.4013394533376875, 0.39598079047977314, 0.39764995172817347, 0.39632884377121, 0.39890877251833656, 0.39921507925490735, 0.3977010941992269, 0.39675701750071846, 0.3943070927868864, 0.3937519192173186, 0.4002683101971547, 0.3983838388842446, 0.3907372638928927, 0.3986506478872134, 0.39147183798259855, 0.3934674683072246, 0.39282810597473017, 0.39158860618051256, 0.39332979746032154, 0.3982678318318661, 0.3972642896467786, 0.39722345699714495, 0.3961678120215813, 0.4005876053293036, 0.4003571712445608, 0.393026083136794, 0.39863396897666076, 0.39289307881753305, 0.3921858529358318, 0.4061537097195611, 0.3957017873764584, 0.3933670958507324, 0.40341815745325327, 0.4012492740814936, 0.40562566703384995, 0.3878630766761971, 0.39245202653639877, 0.39951212380365325, 0.39998625717582176, 0.4028002066217847, 0.3970655513017824, 0.3901285104969033, 0.3903036721656293, 0.3949824818663145, 0.399369762910519, 0.3972432116981611, 0.3992995436909308, 0.39454805543343524, 0.3954548197111479, 0.3912248410695633, 0.3874895305632375, 0.3979426823464996, 0.3917957262073165, 0.39897603134404364, 0.3949629095714559, 0.40084276809264197, 0.3991803208272434, 0.4018236768027055, 0.39876626976085067]

finetune_gin_train_losses = [0.679384758294524545,0.5351038738509529, 0.46149767680007, 0.4066790995107246, 0.37861923447460744, 0.3381358160887008, 0.31717301283071603, 0.2701571032083643, 0.25388016413034425, 0.24797157241961024, 0.24773702555091168, 0.2400284974353601, 0.2328097851180162, 0.22780609242936714, 0.22930765632249275, 0.22607265273450275, 0.22177850009991157, 0.22460017548780198, 0.21631433097729924, 0.21543324373555617, 0.21707739822777877, 0.21889712590701235, 0.2235434101861738, 0.2151441765537457, 0.22077927454313606, 0.2194635148585886, 0.21766585877523092, 0.21720967653268966, 0.2243949728776596, 0.2223015704161318, 0.2157943551675077, 0.22031612055302044, 0.21891574047519355, 0.2191256516237828, 0.22654882910300744, 0.21754399542081668, 0.21928994161034954, 0.21941379548539136, 0.22644758039017046, 0.22117077685153952, 0.22231762964028767, 0.22003862402272767, 0.22272491666769198, 0.22091524726332934, 0.21868506213949523, 0.2175178869338119, 0.22609891917224295, 0.22017908922328883, 0.2195962342956592, 0.21927095570197505, 0.21895661904968092, 0.2195731586966888, 0.21455455805061263, 0.2178393010675711, 0.22274855765412335, 0.2170583479812064, 0.22545855407798773, 0.21879954228870063, 0.21401420810378066, 0.22020455177527493, 0.2235479733890152, 0.2161532110883962, 0.22017261315166067, 0.21658233847227817, 0.21607353449737401, 0.2208564377290588, 0.21947987204183889, 0.22222218822049883, 0.21803336550331595, 0.21574788941614506, 0.21823973179461498, 0.22160092970145143, 0.2174264220694583, 0.21841790719618548, 0.21850227348016088, 0.21417414717356847, 0.22218889797588798, 0.2183297961847162, 0.2215994070504779, 0.22362336324520846, 0.2199715076292269, 0.2171416725595221, 0.22168630970561354, 0.21816682538906507, 0.21398865537827544, 0.22077670261158827, 0.22060548858043458, 0.21543687327568808, 0.21880726562986885, 0.2164546737694041, 0.2167119535665862, 0.2116226943088657, 0.2182341504236492, 0.22324573715965995, 0.21653373597490125, 0.2235126650064571, 0.2200276095269474, 0.21963596140861422, 0.21830166042179616]

finetune_gat_val_losses = [1.07939402365242431, 0.5732735255661061, 0.49055014179510853, 0.44481442688441714, 0.5019125992241322, 0.4656501837697228, 0.5825306025020771, 0.38493302154958087, 0.3692285190904061, 0.374240307266603, 0.3604969613421354, 0.3762955507218016, 0.3617803571960826, 0.3543345949268877, 0.35667887147020677, 0.36455033396761627, 0.364872082732811, 0.36033264653432256, 0.3567541659172974, 0.35999432739799003, 0.3645884634136461, 0.36149728233487843, 0.3606863813977003, 0.35872188882132044, 0.3625324991681925, 0.35933462543528627, 0.36084854292567226, 0.3602847642132206, 0.35937900385495175, 0.3601829693494356, 0.36055900592022666, 0.36336215893631973, 0.3602157882537113, 0.3636206963134357, 0.361345834839914, 0.36175328270386475, 0.3600378400075146, 0.3607791589855656, 0.35977239249914583, 0.3589420628694095, 0.3608678369358344, 0.36219603946237977, 0.36239879170767225, 0.36364452899760386, 0.35977239249914583, 0.36175969274753, 0.358596960437963, 0.3567947777033246, 0.36177239249914583, 0.35677239249914583]

finetune_gat_train_losses = [0.556948384060675,0.5674160955492871, 0.464358527966707, 0.41861614016489596, 0.4022084216993215, 0.41514971955022034, 0.4033280684689017, 0.3136496836533381, 0.2572187606169789, 0.24283206471468807, 0.23652520787394324, 0.22562463861510712, 0.1969227053832933, 0.1857695416730942, 0.1823958327881108, 0.1793865704541827, 0.17977391496973405, 0.1747401776173296, 0.1673688894515432, 0.16641255664281182, 0.16376233225280784, 0.16301441264490324, 0.16594259351671103, 0.16248332456900386, 0.1602736220688868, 0.16558055592850154, 0.16427346101196047, 0.16109878413224932, 0.16283128860693083, 0.16132710122631894, 0.162323951988921, 0.1622764838313068, 0.16209822099252746, 0.16121505105215148, 0.16392603734898, 0.1572918632935751, 0.15886815942375862, 0.1611731416159408, 0.1640666071398313, 0.16406482020607485, 0.15917940207474274, 0.1602438870472616, 0.16100494126414222, 0.16224414604598603,0.1650733202050585,0.15973206707450785,0.16107642054585,0.16210735650508725,0.15787765802050585,0.159434358939485]
finetune_gin_train_losses = finetune_gin_train_losses[:50]
finetune_gin_val_losses = finetune_gin_val_losses[:50]

def chunks(lst, n):
    """Yield successive n-sized chunks from lst."""
    for i in range(0, len(lst), n):
        yield lst[i:i + n]

def smooth(array, weight):
    for value in range(len(array) - 2):
        array[value] = array[value] * weight + (1 - weight) * array[value+1]
    return array

def shorten(array,new_length):
    v = 3*(len(array)-new_length)
    temp = array[-v:]
    temp = chunks(temp,3)
    array = array[:len(array)-int(v)]
    temp = [np.mean(i) for i in temp]
    array.extend(temp)
    return array[:new_length]

df = pd.read_csv('pretraining/GAT/run-GAT_pretraining-tag-train_loss.csv')
gat_train_loss = df['Value']
df = pd.read_csv('pretraining/GAT/run-GAT_pretraining-tag-val_loss.csv')
gat_valid_loss = df['Value']
df = pd.read_csv('pretraining/GIN/run-GIN_pretraining-tag-train_loss.csv')
gin_train_loss = df['Value']
df = pd.read_csv('pretraining/GIN/run-GIN_pretraining-tag-val_loss.csv')
gin_valid_loss = df['Value']

gin_train_loss = shorten(np.array(gin_train_loss).tolist(),150)
gat_train_loss = shorten(np.array(gat_train_loss).tolist(),150)

smth = 0.5
gat_train_loss = smooth(gat_train_loss,smth)
gin_train_loss = smooth(gin_train_loss,smth)
gat_valid_loss = smooth(gat_valid_loss,smth)
gin_valid_loss = smooth(gin_valid_loss,smth)

gat_train_loss = np.array(gat_train_loss).tolist()
gat_valid_loss = np.array(gat_valid_loss).tolist()
gin_train_loss= np.array(gin_train_loss).tolist()
gin_valid_loss = np.array(gin_valid_loss).tolist()
finetune_x_gin = range(150,150+len(finetune_gin_val_losses))
finetune_x_gat = range(150,150+len(finetune_gat_train_losses))

gat_color = 'darkgoldenrod'
gin_color = 'royalblue'
train_style= '-'
val_style= (0, (5, 5))
train_size = 1
val_size = 1

gat_stroke = path_effects.SimpleLineShadow(offset=(0, 0), shadow_color='darkgoldenrod', alpha=0.5, rho=0.3,linewidth=2)
gin_stroke = path_effects.SimpleLineShadow(offset=(0, 0), shadow_color='royalblue', alpha=0.5, rho=0.3,linewidth=3)


plt.figure(figsize=(10.9, 7))
plt.plot(finetune_x_gin,finetune_gin_val_losses,linestyle=val_style,path_effects=[gin_stroke,path_effects.Normal()],linewidth=val_size,color=gin_color)
plt.plot(finetune_x_gat,finetune_gat_val_losses,linestyle=val_style,path_effects=[gat_stroke,path_effects.Normal()],linewidth=val_size,color=gat_color)
plt.plot(finetune_x_gat,finetune_gat_train_losses,linestyle=train_style,path_effects=[gat_stroke,path_effects.Normal()],linewidth=train_size,color=gat_color)
plt.plot(finetune_x_gin,finetune_gin_train_losses,linestyle=train_style,path_effects=[gin_stroke,path_effects.Normal()],linewidth=train_size,color=gin_color)

plt.plot(gat_train_loss,label='GAT-2',linestyle=train_style,path_effects=[gat_stroke,path_effects.Normal()],linewidth=train_size,color=gat_color)
plt.plot(gat_valid_loss,linestyle=val_style,path_effects=[gat_stroke,path_effects.Normal()],linewidth=val_size,color=gat_color)
plt.plot(gin_train_loss,label='GIN-2',linestyle=train_style,path_effects=[gin_stroke,path_effects.Normal()],linewidth=train_size,color=gin_color)
plt.plot(gin_valid_loss,linestyle=val_style,path_effects=[gin_stroke,path_effects.Normal()],linewidth=val_size,color=gin_color)

plt.ylim(0.15,1.6)
plt.xlim(0,200)
plt.legend(prop={'size': 20})
plt.ylabel('Loss',fontsize=16)
plt.xlabel('Epoch',fontsize=16)
plt.axhspan(ymin=0,ymax=2,xmin=0,xmax=150,facecolor='grey',alpha=0.2)
plt.axvspan(ymin=0,ymax=2,xmin=150,xmax=200,facecolor='darkgreen',alpha=0.2)
plt.savefig('pretraining_finetuning_graph.png')
plt.show()
